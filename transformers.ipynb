{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugaybilgis/Desktop/CSC-480/CSC-480-Final-Project/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/vocab.json',\n",
       " 'tokenizer/merges.txt',\n",
       " 'tokenizer/added_tokens.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>1379</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>1380</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>1381</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>1383</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2762 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "2757      1379          1  Dear Senator,\\n\\nI am writing to you today to ...   \n",
       "2758      1380          1  Dear Senator,\\n\\nI am writing to you today to ...   \n",
       "2759      1381          1  Dear Senator,\\n\\nI am writing to you today to ...   \n",
       "2760      1382          1  Dear Senator,\\n\\nI am writing to you today to ...   \n",
       "2761      1383          1  Dear Senator,\\n\\nI am writing to you today to ...   \n",
       "\n",
       "      generated  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "2757          1  \n",
       "2758          1  \n",
       "2759          1  \n",
       "2760          1  \n",
       "2761          1  \n",
       "\n",
       "[2762 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_essay_combined.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, dev_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "train_dataset = datasets.Dataset.from_pandas(train_data)\n",
    "dev_dataset = datasets.Dataset.from_pandas(dev_data)\n",
    "\n",
    "train_dataset =train_dataset.rename_column(\"generated\", \"labels\")\n",
    "dev_dataset =dev_dataset.rename_column(\"generated\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2209/2209 [00:00<00:00, 2787.74 examples/s]\n",
      "Map: 100%|██████████| 553/553 [00:00<00:00, 3452.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\", \"id\", \"prompt_id\"])\n",
    "dev_dataset = dev_dataset.map(preprocess_function, batched=True, remove_columns=[\"text\", \"id\", \"prompt_id\"])\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "dev_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 2209\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import os\n",
    "\n",
    "num_labels = 2\n",
    "device_1 = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"mps\" if torch.backends.mps.is_available() else device_1\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=num_labels).to(device)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = (preds == labels).mean()\n",
    "    print(acc)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9941678, 0.99416465, 0.011102008, 0.9939995, 0.99404377, 0.010408482, 0.9939546, 0.010858155, 0.010413138, 0.9939454, 0.9939465, 0.99409443, 0.017544586, 0.994034, 0.0118556395, 0.010506605, 0.011019036, 0.010840873, 0.010840198, 0.9940446, 0.011236898, 0.9939912, 0.011318469, 0.99404967, 0.010805301, 0.010732793, 0.9940189, 0.011200643, 0.011148697, 0.99398106, 0.9941351, 0.010868115, 0.9941454, 0.010984311, 0.0119889295, 0.99396896, 0.01138982, 0.0105857495, 0.012543207, 0.9941281, 0.012005337, 0.011649064, 0.99417865, 0.010440464, 0.99400914, 0.0109012835, 0.9939442, 0.011973163, 0.012388779, 0.99399287, 0.99409395, 0.010447975, 0.012077607, 0.99396944, 0.012422177, 0.9939335, 0.0139307715, 0.011120906, 0.9942609, 0.99419564, 0.010489112, 0.994083, 0.010950722, 0.014956329, 0.99412894, 0.012284744, 0.9939063, 0.99402976, 0.99398756, 0.010585871, 0.0126536675, 0.9939262, 0.993982, 0.9941684, 0.011479874, 0.010854023, 0.9942075, 0.9940481, 0.011563696, 0.9940959, 0.01173727, 0.013837681, 0.011243225, 0.010850957, 0.011907614, 0.010721508, 0.011683139, 0.011136091, 0.99398625, 0.99400455, 0.9940129, 0.011895233, 0.9940357, 0.9940462, 0.011872202, 0.014869607, 0.9941402, 0.010655532, 0.010623689, 0.010810868, 0.010614536, 0.9939307, 0.02644354, 0.0120924935, 0.013581217, 0.010960549, 0.01084963, 0.011299496, 0.012401059, 0.9942561, 0.011259276, 0.010674107, 0.011877296, 0.9939857, 0.013010395, 0.011247329, 0.9940322, 0.011430543, 0.010638549, 0.99418867, 0.011164389, 0.010842044, 0.013935443, 0.99379236, 0.011119658, 0.011027223, 0.010993251, 0.011127373, 0.9940399, 0.99417526, 0.99425864, 0.0103938, 0.99415886, 0.011448753, 0.9941375, 0.010495013, 0.994132, 0.9939067, 0.012639598, 0.9942139, 0.010700717, 0.99421024, 0.9939459, 0.01101313, 0.01366495, 0.994218, 0.012280463, 0.010497052, 0.9940082, 0.9940626, 0.010573631, 0.010520743, 0.9941056, 0.9940057, 0.994111, 0.010828894, 0.9940925, 0.99418056, 0.99418193, 0.0109090395, 0.9942092, 0.993975, 0.012556941, 0.9940779, 0.99423534, 0.9940499, 0.010461205, 0.9938694, 0.9938793, 0.99414957, 0.99407226, 0.013574864, 0.010753794, 0.994131, 0.99414426, 0.994068, 0.9940836, 0.9940276, 0.9939667, 0.011119752, 0.9939774, 0.9940037, 0.011795366, 0.0110079525, 0.011622839, 0.011206655, 0.9939526, 0.011575982, 0.0107276095, 0.01202533, 0.99391913, 0.013416762, 0.011007397, 0.99418044, 0.99408805, 0.9942061, 0.010535397, 0.011074917, 0.9938778, 0.99407274, 0.011136496, 0.010947686, 0.0117260255, 0.014343157, 0.011009401, 0.9939551, 0.9939672, 0.010731785, 0.9941425, 0.99403507, 0.010737696, 0.011422253, 0.9939182, 0.99410075, 0.010670553, 0.9939568, 0.993995, 0.99395895, 0.012585773, 0.9940063, 0.012122384, 0.99348503, 0.011506641, 0.011255466, 0.020305496, 0.994099, 0.010825451, 0.99393916, 0.0107855955, 0.99396557, 0.011144869, 0.010504643, 0.99398583, 0.0104165, 0.9941386, 0.9941923, 0.99410546, 0.9938591, 0.011110047, 0.9939667, 0.011136482, 0.9939095, 0.9940217, 0.0106542045, 0.013025897, 0.0113479365, 0.011351039, 0.010449492, 0.011422953, 0.014275497, 0.9935753, 0.99391633, 0.99413633, 0.013381614, 0.994086, 0.99424756, 0.011549612, 0.011135656, 0.9939506, 0.9940659, 0.9939679, 0.010466458, 0.010681234, 0.9940064, 0.010640507, 0.9940777, 0.010398526, 0.9940044, 0.9941064, 0.994134, 0.99396414, 0.9939612, 0.9940661, 0.99413365, 0.014648428, 0.99395543, 0.011723445, 0.011010325, 0.010225691, 0.011000973, 0.99402505, 0.011011125, 0.99392337, 0.9941333, 0.99411654, 0.0107433805, 0.9939296, 0.011025861, 0.010965435, 0.010908078, 0.011664885, 0.030741505, 0.99393094, 0.012575603, 0.9939931, 0.9940528, 0.011261119, 0.07072869, 0.010815102, 0.011157411, 0.011033564, 0.9941772, 0.9939944, 0.993919, 0.9938911, 0.9939361, 0.013926456, 0.9938577, 0.012232873, 0.0107563, 0.010563638, 0.9939865, 0.012173317, 0.99410003, 0.9940607, 0.011115036, 0.99401927, 0.010421486, 0.9942409, 0.99403185, 0.011475459, 0.011353502, 0.9939567, 0.99392694, 0.99399096, 0.010808396, 0.9940414, 0.9941047, 0.9942298, 0.9939721, 0.01057385, 0.9939904, 0.9940905, 0.010334217, 0.9941613, 0.9939091, 0.9940095, 0.010854984, 0.013003814, 0.99390393, 0.010546851, 0.016677711, 0.010818362, 0.99395657, 0.9941578, 0.011912283, 0.011035817, 0.99420136, 0.011323274, 0.011757697, 0.99396366, 0.993934, 0.012355178, 0.0115964, 0.011483061, 0.031065267, 0.0111932205, 0.9939857, 0.994155, 0.01088317, 0.011260529, 0.012133262, 0.994052, 0.01182617, 0.011657048, 0.9940096, 0.010577822, 0.0126847, 0.011796839, 0.99398106, 0.011522772, 0.99384946, 0.99400926, 0.9942159, 0.012013332, 0.9939611, 0.011437393, 0.012283447, 0.9939176, 0.9941626, 0.013576671, 0.011185771, 0.011186715, 0.9940216, 0.010923095, 0.9941042, 0.010872314, 0.010475629, 0.9939697, 0.011415761, 0.011675654, 0.011436606, 0.01066481, 0.011100976, 0.01198357, 0.9942159, 0.010924604, 0.99400157, 0.011264039, 0.011165157, 0.013525759, 0.99396086, 0.9941333, 0.99397683, 0.012779639, 0.99390244, 0.9939381, 0.01132495, 0.9939336, 0.9942333, 0.0110771945, 0.010300156, 0.9938075, 0.010532192, 0.010647602, 0.012409086, 0.99397826, 0.99395823, 0.99405754, 0.013673436, 0.9939839, 0.99406296, 0.0105264345, 0.9940965, 0.012749058, 0.9940562, 0.9939248, 0.99398524, 0.011163368, 0.01110159, 0.9941514, 0.010758152, 0.9939805, 0.010611947, 0.010687757, 0.994125, 0.01139692, 0.010635126, 0.0113258995, 0.012227577, 0.9936481, 0.9942597, 0.011078438, 0.01124455, 0.019551361, 0.013879407, 0.011088917, 0.010539017, 0.9941499, 0.9939958, 0.010842376, 0.012037268, 0.011192867, 0.010877992, 0.9942006, 0.0122964885, 0.011132722, 0.01121232, 0.99396956, 0.99415475, 0.9942321, 0.010571366, 0.01061425, 0.0110966265, 0.012048681, 0.010842551, 0.9940348, 0.010619414, 0.99395174, 0.011051994, 0.99390525, 0.9939976, 0.9941454, 0.9940498, 0.01101558, 0.99413586, 0.011372951, 0.99412763, 0.99405825, 0.9939213, 0.017238585, 0.011632845, 0.99404967, 0.994179, 0.011380728, 0.993972, 0.010351568, 0.011679132, 0.013067856, 0.99403834, 0.99419665, 0.9941614, 0.010780213, 0.9941976, 0.9943072, 0.99401456, 0.9939838, 0.9941981, 0.99392575, 0.010535274, 0.01094047, 0.011787987, 0.9939266, 0.011471333, 0.0103930505, 0.01424526, 0.010819749, 0.99408275, 0.99415994, 0.01995339, 0.01096363, 0.9938788, 0.011376271, 0.012249374, 0.9941552, 0.99392855, 0.011427644, 0.013444879, 0.99426633, 0.993954, 0.010896801, 0.9939681, 0.9942545, 0.9939803, 0.99413127, 0.011119884, 0.01050261, 0.9939997, 0.99419135, 0.011306417, 0.9939137, 0.9941983, 0.99393207, 0.99419844, 0.99409497, 0.99394387, 0.99401784, 0.010351574, 0.0123026, 0.010599123, 0.011006089, 0.9942064, 0.9933971, 0.010803212, 0.99405503, 0.99403536, 0.99398094, 0.99412537, 0.99398416, 0.99431854, 0.010842816, 0.9939627, 0.99405354]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(\"./model_tokenizer/model\").to(device)\n",
    "probability_of_llm = []\n",
    "for idx, example in dev_data.iterrows():\n",
    "    tokenized = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
    "    prediction = fine_tuned_model(**tokenized)\n",
    "    probability_of_llm.append(torch.sigmoid(prediction.logits).cpu().detach().numpy()[0][1])\n",
    "\n",
    "# tokenized = tokenizer(test_data[\"text\"].tolist(), padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
    "# prediction = fine_tuned_model(**tokenized)\n",
    "# probability_of_llm = torch.sigmoid(prediction.logits).cpu().detach().numpy()[:, 1]\n",
    "\n",
    "print(probability_of_llm)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
